{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a98d73-512b-46fd-b618-5a1298bccc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>556</td><td>application_1761923966900_0568</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0568/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-189.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0568_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790f885f20564d82b62d5b6ee93252a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>555</td><td>application_1761923966900_0567</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0567/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-43.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0567_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>556</td><td>application_1761923966900_0568</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0568/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-189.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0568_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e0ebb-0746-4980-ba5c-324ec5e5821e",
   "metadata": {},
   "source": [
    "Query 2\n",
    "\n",
    "Ανά έτος, να βρεθούν τα 3 φυλετικά γκρουπ με τα περισσότερα θύματα καταγεγραμμένων εγκλημάτων\n",
    "(Vict Descent) στο Los Angeles. Τα αποτελέσματα να εμφανιστούν με φθίνουσα σειρά αριθμού θυμάτων\n",
    "ανά φυλετικό γκρουπ – να υπολογιστεί και να εμφανιστεί επίσης το ποσοστό επί του συνολικού αριθμού θυμάτων ανα περίπτωση (δείτε παράδειγμα αποτελέσματος στον Πίνακα 2).\n",
    "\n",
    "year Victim Descent # %\n",
    "\n",
    "2024 White 413 32.5\n",
    "\n",
    "2024 Black 274 25.4\n",
    "\n",
    "2024 Unknown 132 22.3\n",
    "\n",
    "2023 Hispanic/Latin/Mexican 512 30.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0345d63-f05e-42f8-a73d-faff18dafa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b86963448f24489829f8430661ebab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----+------------------+\n",
      "|year| descent_description|count|        percentage|\n",
      "+----+--------------------+-----+------------------+\n",
      "|2025|Hispanic/Latin/Me...|   34|35.051546391752574|\n",
      "|2025|             Unknown|   24|24.742268041237114|\n",
      "|2025|Unknown (was not ...|   13|13.402061855670103|\n",
      "|2024|Unknown (was not ...|29204|22.893067956446416|\n",
      "|2024|Hispanic/Latin/Me...|28576|22.400777630578443|\n",
      "|2024|               White|22958|17.996817358721298|\n",
      "|2023|Hispanic/Latin/Me...|69401| 29.86980567690288|\n",
      "|2023|               White|44615|19.202048677613032|\n",
      "|2023|Unknown (was not ...|31497|13.556134196991543|\n",
      "|2022|Hispanic/Latin/Me...|73111|31.076813214372244|\n",
      "|2022|               White|46695| 19.84833736435163|\n",
      "|2022|               Black|34634|14.721647205845473|\n",
      "|2021|Hispanic/Latin/Me...|63676| 30.33981970306276|\n",
      "|2021|               White|44523|21.213954906706817|\n",
      "|2021|               Black|30173|14.376584268806342|\n",
      "|2020|Hispanic/Latin/Me...|61606|30.826582335486645|\n",
      "|2020|               White|42638| 21.33532152096354|\n",
      "|2020|               Black|28785|14.403518691799228|\n",
      "|2019|Hispanic/Latin/Me...|72458|33.098237696306384|\n",
      "|2019|               White|48863|22.320229492321324|\n",
      "+----+--------------------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RDD API Execution time for Query 2: 44.1389 sec"
     ]
    }
   ],
   "source": [
    "#implementation with Dataframes\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "#για μετρηση επιδοσης ολου του implementation\n",
    "start_time = time.time()\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 1 implementation w Dataframes\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the schema for the employees DataFrame\n",
    "crimes_schema = StructType([\n",
    "    StructField(\"dr_no\", StringType()),\n",
    "    StructField(\"date_rptd\", StringType()),\n",
    "    StructField(\"date_occ\", StringType()),\n",
    "    StructField(\"time_occ\", StringType()),\n",
    "    StructField(\"area\", StringType()),\n",
    "    StructField(\"area_name\", StringType()),\n",
    "    StructField(\"rpt_dist_no\", StringType()),\n",
    "    StructField(\"part_1_2\", IntegerType()),\n",
    "    StructField(\"crm_cd\", StringType()),\n",
    "    StructField(\"crm_cd_desc\", StringType()),\n",
    "    StructField(\"mocodes\", StringType()),\n",
    "    StructField(\"vict_age\", StringType()),\n",
    "    StructField(\"vict_sex\", StringType()),\n",
    "    StructField(\"vict_descent\", StringType()),\n",
    "    StructField(\"premis_cd\", StringType()),\n",
    "    StructField(\"premis_desc\", StringType()),\n",
    "    StructField(\"weapon_used_cd\", StringType()),\n",
    "    StructField(\"weapon_desc\", StringType()),\n",
    "    StructField(\"status\", StringType()),\n",
    "    StructField(\"status_desc\", StringType()),\n",
    "    StructField(\"crm_cd_1\",StringType()),\n",
    "    StructField(\"crm_cd_2\",StringType()),\n",
    "    StructField(\"crm_cd_3\",StringType()),\n",
    "    StructField(\"crm_cd_4\",StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"cross_street\", StringType()),\n",
    "    StructField(\"lat\", FloatType()),\n",
    "    StructField(\"lon\", FloatType()),\n",
    "])\n",
    "\n",
    "#Δημιουργούμε ενα λεξικό που αντιστοιχίζει τον κωδικό μεε το φυλετικό γκρούπ\n",
    "descent_dict = {\n",
    "    \"A\": \"Other Asian\",\n",
    "    \"B\": \"Black\",\n",
    "    \"C\": \"Chinese\",\n",
    "    \"D\": \"Cambodian\",\n",
    "    \"F\": \"Filipino\",\n",
    "    \"G\": \"Guamanian\",\n",
    "    \"H\": \"Hispanic/Latin/Mexican\",\n",
    "    \"I\": \"American Indian/Alaskan Native\",\n",
    "    \"J\": \"Japanese\",\n",
    "    \"K\": \"Korean\",\n",
    "    \"L\": \"Laotian\",\n",
    "    \"O\": \"Other\",\n",
    "    \"P\": \"Pacific Islander\",\n",
    "    \"S\": \"Samoan\",\n",
    "    \"U\": \"Hawaiian\",\n",
    "    \"V\": \"Vietnamese\",\n",
    "    \"W\": \"White\",\n",
    "    \"X\": \"Unknown\",\n",
    "    \"Z\": \"Asian Indian\"\n",
    "}\n",
    "#Μετατρεπουμε το λεξικό σε Dataframe και μετα θα το κανουμε left join για να αντιστοιχίσουμε τον κωδικο με το γκρουπ\n",
    "descent_rows = [(k, v) for k, v in descent_dict.items()]\n",
    "descent_df = spark.createDataFrame(descent_rows, [\"vict_descent\", \"descent_description\"])\n",
    "\n",
    "crimes_2010_2019_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=crimes_schema)\n",
    "\n",
    "crimes_2020_2025_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "                                     header=False, \\\n",
    "                                     schema=crimes_schema)\n",
    "\n",
    "#Union both datasets to have all the data available for the query\n",
    "crimes_total_df = crimes_2010_2019_df.union(crimes_2020_2025_df)\n",
    "\n",
    "#Απο το StringType προσθέτουμε καινουριο column \"year\" που ουσιαστικά ειναι οι πρωτοι 4 χαρακτήρες του sting απο date_occ\n",
    "years_df = crimes_total_df.withColumn(\"year\", F.substring(\"date_occ\", 1, 4).cast(\"int\"))\n",
    "\n",
    "#years_df.show(10)\n",
    "#Για καθε χρονια θα βρουμε τις τρεις φυλετικες κατηγοριες με τα περισσοτερα περιστατικά\n",
    "#θα βαλουμε ολες τις χρονιες σε μια λιστα και μετα για καθε στοιχειο τις λιστας που συμπηπτει με τον χρονο στο \n",
    "\n",
    "def top3_racial_groups_per_year(df):\n",
    "\n",
    "    \n",
    "    # 2. get distinct years\n",
    "    years = [row[\"year\"] for row in df.select(\"year\").distinct().collect()]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for y in years:\n",
    "        # όλα τα incidents του έτους y\n",
    "        df_year = df.filter(F.col(\"year\") == y)\n",
    "        \n",
    "        total = df_year.count()\n",
    "        if total == 0:\n",
    "            continue\n",
    "        \n",
    "        # count per racial group\n",
    "        groups = (\n",
    "            df_year.groupBy(\"vict_descent\")\n",
    "                   .count()\n",
    "                   .orderBy(F.col(\"count\").desc())\n",
    "        )\n",
    "        \n",
    "        top3 = groups.limit(3).collect()\n",
    "        \n",
    "        # αποθήκευση αποτελεσμάτων\n",
    "        for row in top3:\n",
    "            vict = row[\"vict_descent\"]\n",
    "            c = row[\"count\"]\n",
    "            pct = (c / total) * 100\n",
    "            \n",
    "            results.append(\n",
    "                Row(\n",
    "                    year=y,\n",
    "                    vict_descent=vict,\n",
    "                    count=c,\n",
    "                    total=total,\n",
    "                    percentage=pct\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # δημιουργεί τελικό DataFrame\n",
    "    spark = df.sparkSession\n",
    "    result_df = spark.createDataFrame(results)\n",
    "\n",
    "    # ταξινόμηση αποτελεσμάτων\n",
    "    result_df = result_df.join(descent_df, on=\"vict_descent\", how=\"left\")\n",
    "    result_df = result_df.withColumn(\"descent_description\", F.when(F.col(\"descent_description\").isNull(), \"Unknown (was not filed)\").otherwise(F.col(\"descent_description\")))\n",
    "    result_df = result_df.drop(\"total\").select(\"year\",\"descent_description\", \"count\", \"percentage\")\n",
    "    result_df = result_df.orderBy(F.col(\"year\").desc(), F.col(\"count\").desc())\n",
    "    return result_df\n",
    "\n",
    "total_res_df = top3_racial_groups_per_year(years_df)\n",
    "#result_df = result_df.drop(\"total\").select(\"year\",\"descent_description\", \"count\", \"percentage\")\n",
    "total_res_df.show()\n",
    "end_time= time.time()\n",
    "print(\"RDD API Execution time for Query 2: {:.4f} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97f910d0-1472-4e02-9062-948a39d52ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6581b223b7419abab633e194cdc259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+-----------------------+-----+------+----------+\n",
      "|year|vict_descent|descent_description    |count|total |percentage|\n",
      "+----+------------+-----------------------+-----+------+----------+\n",
      "|2025|H           |Hispanic/Latin/Mexican |34   |97    |35.05     |\n",
      "|2025|X           |Unknown                |24   |97    |24.74     |\n",
      "|2025|NULL        |Unknown (was not filed)|13   |97    |13.4      |\n",
      "|2024|NULL        |Unknown (was not filed)|29204|127567|22.89     |\n",
      "|2024|H           |Hispanic/Latin/Mexican |28576|127567|22.4      |\n",
      "|2024|W           |White                  |22958|127567|18.0      |\n",
      "|2023|H           |Hispanic/Latin/Mexican |69401|232345|29.87     |\n",
      "|2023|W           |White                  |44615|232345|19.2      |\n",
      "|2023|NULL        |Unknown (was not filed)|31497|232345|13.56     |\n",
      "|2022|H           |Hispanic/Latin/Mexican |73111|235259|31.08     |\n",
      "|2022|W           |White                  |46695|235259|19.85     |\n",
      "|2022|B           |Black                  |34634|235259|14.72     |\n",
      "|2021|H           |Hispanic/Latin/Mexican |63676|209876|30.34     |\n",
      "|2021|W           |White                  |44523|209876|21.21     |\n",
      "|2021|B           |Black                  |30173|209876|14.38     |\n",
      "|2020|H           |Hispanic/Latin/Mexican |61606|199847|30.83     |\n",
      "|2020|W           |White                  |42638|199847|21.34     |\n",
      "|2020|B           |Black                  |28785|199847|14.4      |\n",
      "|2019|H           |Hispanic/Latin/Mexican |72458|218918|33.1      |\n",
      "|2019|W           |White                  |48863|218918|22.32     |\n",
      "|2019|B           |Black                  |33157|218918|15.15     |\n",
      "|2018|H           |Hispanic/Latin/Mexican |75958|229768|33.06     |\n",
      "|2018|W           |White                  |52233|229768|22.73     |\n",
      "|2018|B           |Black                  |35340|229768|15.38     |\n",
      "|2017|H           |Hispanic/Latin/Mexican |78308|231751|33.79     |\n",
      "|2017|W           |White                  |52744|231751|22.76     |\n",
      "|2017|B           |Black                  |34713|231751|14.98     |\n",
      "|2016|H           |Hispanic/Latin/Mexican |99135|283798|34.93     |\n",
      "|2016|W           |White                  |63760|283798|22.47     |\n",
      "|2016|B           |Black                  |42449|283798|14.96     |\n",
      "|2015|H           |Hispanic/Latin/Mexican |55978|168076|33.31     |\n",
      "|2015|W           |White                  |44102|168076|26.24     |\n",
      "|2015|B           |Black                  |26510|168076|15.77     |\n",
      "|2014|H           |Hispanic/Latin/Mexican |68763|195879|35.1      |\n",
      "|2014|W           |White                  |47531|195879|24.27     |\n",
      "|2014|B           |Black                  |32952|195879|16.82     |\n",
      "|2013|H           |Hispanic/Latin/Mexican |66741|192875|34.6      |\n",
      "|2013|W           |White                  |48453|192875|25.12     |\n",
      "|2013|B           |Black                  |31975|192875|16.58     |\n",
      "|2012|H           |Hispanic/Latin/Mexican |70338|201835|34.85     |\n",
      "|2012|W           |White                  |51839|201835|25.68     |\n",
      "|2012|B           |Black                  |33572|201835|16.63     |\n",
      "|2011|H           |Hispanic/Latin/Mexican |70845|200912|35.26     |\n",
      "|2011|W           |White                  |51219|200912|25.49     |\n",
      "|2011|B           |Black                  |32579|200912|16.22     |\n",
      "|2010|H           |Hispanic/Latin/Mexican |73558|209325|35.14     |\n",
      "|2010|W           |White                  |53835|209325|25.72     |\n",
      "|2010|B           |Black                  |33937|209325|16.21     |\n",
      "|NULL|Vict Descent|Unknown (was not filed)|2    |2     |100.0     |\n",
      "+----+------------+-----------------------+-----+------+----------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (27)\n",
      "+- Sort (26)\n",
      "   +- Exchange (25)\n",
      "      +- Project (24)\n",
      "         +- Filter (23)\n",
      "            +- Window (22)\n",
      "               +- WindowGroupLimit (21)\n",
      "                  +- Sort (20)\n",
      "                     +- Project (19)\n",
      "                        +- Window (18)\n",
      "                           +- Sort (17)\n",
      "                              +- Exchange (16)\n",
      "                                 +- HashAggregate (15)\n",
      "                                    +- HashAggregate (14)\n",
      "                                       +- Project (13)\n",
      "                                          +- SortMergeJoin LeftOuter (12)\n",
      "                                             :- Sort (7)\n",
      "                                             :  +- Exchange (6)\n",
      "                                             :     +- Union (5)\n",
      "                                             :        :- Project (2)\n",
      "                                             :        :  +- Scan csv  (1)\n",
      "                                             :        +- Project (4)\n",
      "                                             :           +- Scan csv  (3)\n",
      "                                             +- Sort (11)\n",
      "                                                +- Exchange (10)\n",
      "                                                   +- Filter (9)\n",
      "                                                      +- Scan ExistingRDD (8)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [2]: [date_occ#43968, vict_descent#43979]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv]\n",
      "ReadSchema: struct<date_occ:string,vict_descent:string>\n",
      "\n",
      "(2) Project\n",
      "Output [2]: [vict_descent#43979, cast(substring(date_occ#43968, 1, 4) as int) AS year#44110]\n",
      "Input [2]: [date_occ#43968, vict_descent#43979]\n",
      "\n",
      "(3) Scan csv \n",
      "Output [2]: [date_occ#44024, vict_descent#44035]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv]\n",
      "ReadSchema: struct<date_occ:string,vict_descent:string>\n",
      "\n",
      "(4) Project\n",
      "Output [2]: [vict_descent#44035, cast(substring(date_occ#44024, 1, 4) as int) AS year#44206]\n",
      "Input [2]: [date_occ#44024, vict_descent#44035]\n",
      "\n",
      "(5) Union\n",
      "\n",
      "(6) Exchange\n",
      "Input [2]: [vict_descent#43979, year#44110]\n",
      "Arguments: hashpartitioning(vict_descent#43979, 1000), ENSURE_REQUIREMENTS, [plan_id=43027]\n",
      "\n",
      "(7) Sort\n",
      "Input [2]: [vict_descent#43979, year#44110]\n",
      "Arguments: [vict_descent#43979 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(8) Scan ExistingRDD\n",
      "Output [2]: [vict_descent#44078, descent_description#44079]\n",
      "Arguments: [vict_descent#44078, descent_description#44079], MapPartitionsRDD[5294] at applySchemaToPythonRDD at <unknown>:0, ExistingRDD, UnknownPartitioning(0)\n",
      "\n",
      "(9) Filter\n",
      "Input [2]: [vict_descent#44078, descent_description#44079]\n",
      "Condition : isnotnull(vict_descent#44078)\n",
      "\n",
      "(10) Exchange\n",
      "Input [2]: [vict_descent#44078, descent_description#44079]\n",
      "Arguments: hashpartitioning(vict_descent#44078, 1000), ENSURE_REQUIREMENTS, [plan_id=43028]\n",
      "\n",
      "(11) Sort\n",
      "Input [2]: [vict_descent#44078, descent_description#44079]\n",
      "Arguments: [vict_descent#44078 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(12) SortMergeJoin\n",
      "Left keys [1]: [vict_descent#43979]\n",
      "Right keys [1]: [vict_descent#44078]\n",
      "Join type: LeftOuter\n",
      "Join condition: None\n",
      "\n",
      "(13) Project\n",
      "Output [3]: [year#44110, vict_descent#43979, coalesce(descent_description#44079, Unknown (was not filed)) AS descent_description#44140]\n",
      "Input [4]: [vict_descent#43979, year#44110, vict_descent#44078, descent_description#44079]\n",
      "\n",
      "(14) HashAggregate\n",
      "Input [3]: [year#44110, vict_descent#43979, descent_description#44140]\n",
      "Keys [3]: [year#44110, vict_descent#43979, descent_description#44140]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#44193L]\n",
      "Results [4]: [year#44110, vict_descent#43979, descent_description#44140, count#44194L]\n",
      "\n",
      "(15) HashAggregate\n",
      "Input [4]: [year#44110, vict_descent#43979, descent_description#44140, count#44194L]\n",
      "Keys [3]: [year#44110, vict_descent#43979, descent_description#44140]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#44145L]\n",
      "Results [4]: [year#44110, vict_descent#43979, descent_description#44140, count(1)#44145L AS count#44144L]\n",
      "\n",
      "(16) Exchange\n",
      "Input [4]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L]\n",
      "Arguments: hashpartitioning(year#44110, 1000), ENSURE_REQUIREMENTS, [plan_id=43036]\n",
      "\n",
      "(17) Sort\n",
      "Input [4]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L]\n",
      "Arguments: [year#44110 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(18) Window\n",
      "Input [4]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L]\n",
      "Arguments: [sum(count#44144L) windowspecdefinition(year#44110, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS total_per_year#44150L], [year#44110]\n",
      "\n",
      "(19) Project\n",
      "Output [6]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total_per_year#44150L AS total#44157L, round(((cast(count#44144L as double) / cast(total_per_year#44150L as double)) * 100.0), 2) AS percentage#44158]\n",
      "Input [5]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total_per_year#44150L]\n",
      "\n",
      "(20) Sort\n",
      "Input [6]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total#44157L, percentage#44158]\n",
      "Arguments: [year#44110 ASC NULLS FIRST, count#44144L DESC NULLS LAST], false, 0\n",
      "\n",
      "(21) WindowGroupLimit\n",
      "Input [6]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total#44157L, percentage#44158]\n",
      "Arguments: [year#44110], [count#44144L DESC NULLS LAST], row_number(), 3, Final\n",
      "\n",
      "(22) Window\n",
      "Input [6]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total#44157L, percentage#44158]\n",
      "Arguments: [row_number() windowspecdefinition(year#44110, count#44144L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#44159], [year#44110], [count#44144L DESC NULLS LAST]\n",
      "\n",
      "(23) Filter\n",
      "Input [7]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total#44157L, percentage#44158, rn#44159]\n",
      "Condition : (rn#44159 <= 3)\n",
      "\n",
      "(24) Project\n",
      "Output [6]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total#44157L, percentage#44158]\n",
      "Input [7]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total#44157L, percentage#44158, rn#44159]\n",
      "\n",
      "(25) Exchange\n",
      "Input [6]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total#44157L, percentage#44158]\n",
      "Arguments: rangepartitioning(year#44110 DESC NULLS LAST, count#44144L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=43054]\n",
      "\n",
      "(26) Sort\n",
      "Input [6]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total#44157L, percentage#44158]\n",
      "Arguments: [year#44110 DESC NULLS LAST, count#44144L DESC NULLS LAST], true, 0\n",
      "\n",
      "(27) AdaptiveSparkPlan\n",
      "Output [6]: [year#44110, vict_descent#43979, descent_description#44140, count#44144L, total#44157L, percentage#44158]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "SQL API Execution time for Query 2: 32.6514 sec"
     ]
    }
   ],
   "source": [
    "# Implementation 2: SQL API\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 2 w SQL API\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "crimes_schema = StructType([\n",
    "    StructField(\"dr_no\", StringType()),\n",
    "    StructField(\"date_rptd\", StringType()),\n",
    "    StructField(\"date_occ\", StringType()),\n",
    "    StructField(\"time_occ\", StringType()),\n",
    "    StructField(\"area\", StringType()),\n",
    "    StructField(\"area_name\", StringType()),\n",
    "    StructField(\"rpt_dist_no\", StringType()),\n",
    "    StructField(\"part_1_2\", IntegerType()),\n",
    "    StructField(\"crm_cd\", StringType()),\n",
    "    StructField(\"crm_cd_desc\", StringType()),\n",
    "    StructField(\"mocodes\", StringType()),\n",
    "    StructField(\"vict_age\", StringType()),\n",
    "    StructField(\"vict_sex\", StringType()),\n",
    "    StructField(\"vict_descent\", StringType()),\n",
    "    StructField(\"premis_cd\", StringType()),\n",
    "    StructField(\"premis_desc\", StringType()),\n",
    "    StructField(\"weapon_used_cd\", StringType()),\n",
    "    StructField(\"weapon_desc\", StringType()),\n",
    "    StructField(\"status\", StringType()),\n",
    "    StructField(\"status_desc\", StringType()),\n",
    "    StructField(\"crm_cd_1\",StringType()),\n",
    "    StructField(\"crm_cd_2\",StringType()),\n",
    "    StructField(\"crm_cd_3\",StringType()),\n",
    "    StructField(\"crm_cd_4\",StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"cross_street\", StringType()),\n",
    "    StructField(\"lat\", FloatType()),\n",
    "    StructField(\"lon\", FloatType()),\n",
    "])\n",
    "\n",
    "crimes_2010_2019_df = spark.read.format('csv') \\\n",
    "    .options(header='false') \\\n",
    "    .schema(crimes_schema) \\\n",
    "    .load(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\")\n",
    "\n",
    "crimes_2020_2025_df = spark.read.format('csv') \\\n",
    "    .options(header='false') \\\n",
    "    .schema(crimes_schema) \\\n",
    "    .load(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\")\n",
    "\n",
    "#Δημιουργούμε ενα λεξικό που αντιστοιχίζει τον κωδικό μεε το φυλετικό γκρούπ\n",
    "descent_dict = {\n",
    "    \"A\": \"Other Asian\",\n",
    "    \"B\": \"Black\",\n",
    "    \"C\": \"Chinese\",\n",
    "    \"D\": \"Cambodian\",\n",
    "    \"F\": \"Filipino\",\n",
    "    \"G\": \"Guamanian\",\n",
    "    \"H\": \"Hispanic/Latin/Mexican\",\n",
    "    \"I\": \"American Indian/Alaskan Native\",\n",
    "    \"J\": \"Japanese\",\n",
    "    \"K\": \"Korean\",\n",
    "    \"L\": \"Laotian\",\n",
    "    \"O\": \"Other\",\n",
    "    \"P\": \"Pacific Islander\",\n",
    "    \"S\": \"Samoan\",\n",
    "    \"U\": \"Hawaiian\",\n",
    "    \"V\": \"Vietnamese\",\n",
    "    \"W\": \"White\",\n",
    "    \"X\": \"Unknown\",\n",
    "    \"Z\": \"Asian Indian\"\n",
    "}\n",
    "\n",
    "#Μετατρεπουμε το λεξικό σε Dataframe και μετα θα το κανουμε left join για να αντιστοιχίσουμε τον κωδικο με το γκρουπ\n",
    "descent_rows = [(k, v) for k, v in descent_dict.items()]\n",
    "descent_df = spark.createDataFrame(descent_rows, [\"vict_descent\", \"descent_description\"])\n",
    "\n",
    "crimes_total_df = crimes_2010_2019_df.union(crimes_2020_2025_df)\n",
    "\n",
    "#Απο το StringType προσθέτουμε καινουριο column \"year\" που ουσιαστικά ειναι οι πρωτοι 4 χαρακτήρες του sting απο date_occ\n",
    "years_df = crimes_total_df.withColumn(\"year\", F.substring(\"date_occ\", 1, 4).cast(\"int\"))\n",
    "# To utilize as SQL tables\n",
    "years_df.createOrReplaceTempView(\"crimes\")\n",
    "descent_df.createOrReplaceTempView(\"descent\")\n",
    "\n",
    "#κανουμε join για να εχουμε το description\n",
    "join_query = \" \\\n",
    "    SELECT \\\n",
    "        c.year, \\\n",
    "        c.vict_descent, \\\n",
    "        COALESCE(d.descent_description, 'Unknown (was not filed)') AS descent_description \\\n",
    "    FROM crimes c \\\n",
    "    LEFT JOIN descent d \\\n",
    "        ON c.vict_descent = d.vict_descent \\\n",
    "\"\n",
    "\n",
    "joined_df = spark.sql(join_query)\n",
    "joined_df.createOrReplaceTempView(\"joined\")\n",
    "\n",
    "count_query = \" \\\n",
    "    SELECT \\\n",
    "        year, \\\n",
    "        vict_descent, \\\n",
    "        descent_description, \\\n",
    "        COUNT(*) AS count \\\n",
    "    FROM joined \\\n",
    "    GROUP BY year, vict_descent, descent_description \\\n",
    "\"\n",
    "\n",
    "counts_df = spark.sql(count_query)\n",
    "counts_df.createOrReplaceTempView(\"counts\")\n",
    "\n",
    "totals_query = \" \\\n",
    "    SELECT \\\n",
    "        *, \\\n",
    "        SUM(count) OVER (PARTITION BY year) AS total_per_year \\\n",
    "    FROM counts \\\n",
    "\"\n",
    "\n",
    "totals_df = spark.sql(totals_query)\n",
    "totals_df.createOrReplaceTempView(\"with_totals\")\n",
    "\n",
    "rank_query = \" \\\n",
    "    SELECT \\\n",
    "        year, \\\n",
    "        vict_descent, \\\n",
    "        descent_description, \\\n",
    "        count, \\\n",
    "        total_per_year AS total, \\\n",
    "        ROUND((count / total_per_year) * 100, 2) AS percentage, \\\n",
    "        ROW_NUMBER() OVER (PARTITION BY year ORDER BY count DESC) AS rn \\\n",
    "    FROM with_totals \\\n",
    "\"\n",
    "\n",
    "ranked_df = spark.sql(rank_query)\n",
    "ranked_df.createOrReplaceTempView(\"ranked\")\n",
    "\n",
    "final_query = \" \\\n",
    "    SELECT \\\n",
    "        year, \\\n",
    "        vict_descent, \\\n",
    "        descent_description, \\\n",
    "        count, \\\n",
    "        total, \\\n",
    "        percentage \\\n",
    "    FROM ranked \\\n",
    "    WHERE rn <= 3 \\\n",
    "    ORDER BY year DESC, count DESC \\\n",
    "\"\n",
    "\n",
    "result_sql_df = spark.sql(final_query)\n",
    "result_sql_df.show(100, truncate=False)\n",
    "result_sql_df.explain(mode='formatted')\n",
    "end_time=time.time()\n",
    "print(\"SQL API Execution time for Query 2: {:.4f} sec\".format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5d18a-86c6-45b5-b297-4711a552a52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
