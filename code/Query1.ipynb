{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f29518d1-0b48-4afc-9399-76522183fdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>849</td><td>application_1761923966900_0861</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0861/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-160.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0861_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f122a8649a4bf1a593bb9c7aea4055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>847</td><td>application_1761923966900_0859</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0859/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-189.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0859_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>848</td><td>application_1761923966900_0860</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0860/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-97.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0860_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>849</td><td>application_1761923966900_0861</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0861/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-160.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0861_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bd94d-d745-439c-a3eb-9e6c1e880871",
   "metadata": {},
   "source": [
    "#Query 1 \n",
    "Να ταξινομηθούν, σε φθίνουσα σειρά, οι ηλικιακές ομάδες των θυμάτων σε περιστατικά που περιλαμβάνουν οποιαδήποτε μορφή “βαριάς σωματικής βλάβης”.   \n",
    "\n",
    "Θεωρείστε τις εξής ηλικιακές ομάδες:\n",
    "\n",
    "\n",
    "• Παιδιά: < 18\n",
    "\n",
    "• Νεαροί ενήλικοι: 18 – 24\n",
    "\n",
    "• Ενήλικοι: 25 – 64\n",
    "\n",
    "• Ηλικιωμένοι: >64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad1920-4030-4135-9173-5bec12bcc5b3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Dataframes Implementetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a78cddad-67ac-4e38-b72b-83d691416839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435bdc28517e489f9519e20591303840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|age_group| count|\n",
      "+---------+------+\n",
      "|   Adults|121660|\n",
      "|    Youth| 33758|\n",
      "| Children| 16009|\n",
      "|  Seniors|  6011|\n",
      "|  Unknown|     5|\n",
      "+---------+------+\n",
      "\n",
      "Dataframe API Execution time for Query 1: 33.6270 sec"
     ]
    }
   ],
   "source": [
    "# Implementation with DataFrame API\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "import time \n",
    "\n",
    "start_time=time.time()\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 1 implementation w Dataframes\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "crimes_schema = StructType([\n",
    "    StructField(\"dr_no\", StringType()),\n",
    "    StructField(\"date_rptd\", StringType()),\n",
    "    StructField(\"date_occ\", StringType()),\n",
    "    StructField(\"time_occ\", StringType()),\n",
    "    StructField(\"area\", StringType()),\n",
    "    StructField(\"area_name\", StringType()),\n",
    "    StructField(\"rpt_dist_no\", StringType()),\n",
    "    StructField(\"part_1_2\", IntegerType()),\n",
    "    StructField(\"crm_cd\", StringType()),\n",
    "    StructField(\"crm_cd_desc\", StringType()),\n",
    "    StructField(\"mocodes\", StringType()),\n",
    "    StructField(\"vict_age\", StringType()),\n",
    "    StructField(\"vict_sex\", StringType()),\n",
    "    StructField(\"vict_descent\", StringType()),\n",
    "    StructField(\"premis_cd\", StringType()),\n",
    "    StructField(\"premis_desc\", StringType()),\n",
    "    StructField(\"weapon_used_cd\", StringType()),\n",
    "    StructField(\"weapon_desc\", StringType()),\n",
    "    StructField(\"status\", StringType()),\n",
    "    StructField(\"status_desc\", StringType()),\n",
    "    StructField(\"crm_cd_1\",StringType()),\n",
    "    StructField(\"crm_cd_2\",StringType()),\n",
    "    StructField(\"crm_cd_3\",StringType()),\n",
    "    StructField(\"crm_cd_4\",StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"cross_street\", StringType()),\n",
    "    StructField(\"lat\", FloatType()),\n",
    "    StructField(\"lon\", FloatType()),\n",
    "])\n",
    "\n",
    "\n",
    "crimes_2010_2019_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=crimes_schema)\n",
    "\n",
    "crimes_2020_2025_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "                                     header=False, \\\n",
    "                                     schema=crimes_schema)\n",
    "\n",
    "\n",
    "#Union both datasets to have all the data available for the query\n",
    "crimes_total_df = crimes_2010_2019_df.union(crimes_2020_2025_df)\n",
    "\n",
    "#Βρίσκουμε όλα τα εγκλήματα που έχουν προκαλέσει βαριά σωματική βλάβη \n",
    "assault_df = crimes_total_df.filter(col(\"crm_cd_desc\").like(\"%AGGRAVATED ASSAULT%\"))\n",
    "\n",
    "#μετατρεπουμε την μεταβλητη απο τύπο Sting σε τύπο int για να εχουμε συγκριση\n",
    "test_df = assault_df.withColumn(\"vict_age_int\", col(\"vict_age\").cast(\"integer\"))\n",
    "#φτιαχνουμε το ζητούμενο dataset το οποίο περιέχει την ηλικιακή ομάδα του θύυματος και έπειτα το πληθος των περιστατικών\n",
    "age_groups_counts = (\n",
    "    test_df\n",
    "    .withColumn(\n",
    "        \"age_group\",\n",
    "        F.when((col(\"vict_age_int\") >= 0) & (col(\"vict_age_int\") < 18), \"Children\")\n",
    "         .when((col(\"vict_age_int\") >= 18) & (col(\"vict_age_int\") < 25), \"Youth\")\n",
    "         .when((col(\"vict_age_int\") >= 25) & (col(\"vict_age_int\") < 65), \"Adults\")\n",
    "         .when(col(\"vict_age_int\") >= 65, \"Seniors\")\n",
    "         .otherwise(\"Unknown\")\n",
    "    )\n",
    "    .groupBy(\"age_group\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    ")\n",
    "\n",
    "age_groups_counts.show()\n",
    "end_time=time.time()\n",
    "print(\"Dataframe API Execution time for Query 1: {:.4f} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c73dc16e-e108-42ab-bf59-5ab666095c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90720023b4e149bf8b47877c41490954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 23, 36, 0, 32]\n",
      "[('????????', 21477), ('??????', 5892), ('??????', 2794), ('???????????', 510)]\n",
      "Children: 2794\n",
      "Youth: 5892\n",
      "Adults: 21477\n",
      "Seniors: 510\n",
      "RDD API Execution time for Query 1: 39.5206 sec"
     ]
    }
   ],
   "source": [
    "# Implementation with RDD API\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "sc = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 1 implementation w RDD\") \\\n",
    "    .getOrCreate() \\\n",
    "    .sparkContext\n",
    "    \n",
    "# Load and process data\n",
    "\n",
    "crimes_2010_2019 = sc.textFile(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\") \\\n",
    "                .map(lambda x: (x.split(\",\"))) # Split lines into a list of elements -> delimiter: \",\"\n",
    "\n",
    "crimes_2020_2025 = sc.textFile(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\") \\\n",
    "                .map(lambda x: (x.split(\",\"))) # Split lines into a list of elements -> delimiter: \",\"\n",
    "\n",
    "\n",
    "crimes=crimes_2010_2019.union(crimes_2020_2025)\n",
    "\n",
    "#Ψαχνουμε μόνο τα εγκλήματα που έχουν σχέση με βαριά σωματική βλάβη -> δηλαδή ψάωνουμε aggravated assault \n",
    "assault_rdd = crimes.filter(\n",
    "    lambda row: \"AGGRAVATED ASSAULT\" in row[9].upper()\n",
    ")\n",
    "\n",
    "#μετατρεπουμε τις ηλικιες απο στρινγκ σε ιντ και αποθηκευουμε σε καινουριο rdd μονο τις τιμες των ηλικιων για ολα τα στοιχεια που υπαρχουν στο assault_rdd \n",
    "#μετα απο debugging το προβλημα ηταν οτι τα στοιχεια ηταν φωλιασμενα μεσα σε \"\", οπότε κανουμε replace με απλά για τα strings\n",
    "ages_rdd = assault_rdd.map(lambda row: int(row[11].replace('\"', '')))\n",
    "print(ages_rdd.take(5))\n",
    "\n",
    "children_rdd = ages_rdd.filter(lambda age:  age< 18)\n",
    "youths_rdd = ages_rdd.filter(lambda age:  18 <= age <= 24)\n",
    "adults_rdd = ages_rdd.filter(lambda age: 25 <= age < 64)\n",
    "seniors_rdd = ages_rdd.filter(lambda age: age >= 64)\n",
    "\n",
    "#ftiaxnoyme mia lista me tuples (age group, incidents of Aggravated assault)\n",
    "counts_list = [\n",
    "    (\"Παιδιά\", children_rdd.count()),\n",
    "    (\"Νεαροί\", youths_rdd.count()),\n",
    "    (\"Ενήλικοι\", adults_rdd.count()),\n",
    "    (\"Ηλικιωμένοι\", seniors_rdd.count())\n",
    "]\n",
    "\n",
    "# Δημιουργούμε RDD από τη λίστα\n",
    "counts_rdd = sc.parallelize(counts_list)\n",
    "\n",
    "sorted_counts_rdd = counts_rdd.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "print(sorted_counts_rdd.collect())\n",
    "print(\"Children:\", children_rdd.count())\n",
    "print(\"Youth:\", youths_rdd.count())\n",
    "print(\"Adults:\", adults_rdd.count())\n",
    "print(\"Seniors:\", seniors_rdd.count())\n",
    "end_time = time.time()\n",
    "print(\"RDD API Execution time for Query 1: {:.4f} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b270b68-0751-4aa4-8bd2-f0f87e93fdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a50fe3c1cc04c69a2d21340867dbda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "invalid syntax (<stdin>, line 1)\n",
      "  File \"<stdin>\", line 1\n",
      "    ---------+------+\n",
      "                     ^\n",
      "SyntaxError: invalid syntax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "---------+------+\n",
    "|   Adults|121660|\n",
    "|    Youth| 33758|\n",
    "| Children| 16009|\n",
    "|  Seniors|  6011|\n",
    "|  Unknown|     5|\n",
    "+---------+------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb6212eb-15fb-4ab7-9851-fc58a16a58ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e365598a9b4ec68f619b27f5bf63a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|age_group| count|\n",
      "+---------+------+\n",
      "|   Adults|121660|\n",
      "|   Youths| 33758|\n",
      "| Children| 16014|\n",
      "|  Seniors|  6011|\n",
      "+---------+------+\n",
      "\n",
      "Dataframe using UDF API Execution time for Query 1: 6.1317 sec"
     ]
    }
   ],
   "source": [
    "#Implementation with Dataframes using UDFs\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "from pyspark.sql.functions import col, udf\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Query 1 implementation w Dataframes using UDF\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "crimes_schema = StructType([\n",
    "    StructField(\"dr_no\", StringType()),\n",
    "    StructField(\"date_rptd\", StringType()),\n",
    "    StructField(\"date_occ\", StringType()),\n",
    "    StructField(\"time_occ\", StringType()),\n",
    "    StructField(\"area\", StringType()),\n",
    "    StructField(\"area_name\", StringType()),\n",
    "    StructField(\"rpt_dist_no\", StringType()),\n",
    "    StructField(\"part_1_2\", IntegerType()),\n",
    "    StructField(\"crm_cd\", StringType()),\n",
    "    StructField(\"crm_cd_desc\", StringType()),\n",
    "    StructField(\"mocodes\", StringType()),\n",
    "    StructField(\"vict_age\", StringType()),\n",
    "    StructField(\"vict_sex\", StringType()),\n",
    "    StructField(\"vict_descent\", StringType()),\n",
    "    StructField(\"premis_cd\", StringType()),\n",
    "    StructField(\"premis_desc\", StringType()),\n",
    "    StructField(\"weapon_used_cd\", StringType()),\n",
    "    StructField(\"weapon_desc\", StringType()),\n",
    "    StructField(\"status\", StringType()),\n",
    "    StructField(\"status_desc\", StringType()),\n",
    "    StructField(\"crm_cd_1\",StringType()),\n",
    "    StructField(\"crm_cd_2\",StringType()),\n",
    "    StructField(\"crm_cd_3\",StringType()),\n",
    "    StructField(\"crm_cd_4\",StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"cross_street\", StringType()),\n",
    "    StructField(\"lat\", FloatType()),\n",
    "    StructField(\"lon\", FloatType()),\n",
    "])\n",
    "\n",
    "\n",
    "crimes_2010_2019_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=crimes_schema)\n",
    "\n",
    "crimes_2020_2025_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "                                     header=False, \\\n",
    "                                     schema=crimes_schema)\n",
    "\n",
    "#Union both datasets to have all the data available for the query\n",
    "crimes_total_df = crimes_2010_2019_df.union(crimes_2020_2025_df)\n",
    "\n",
    "#Βρίσκουμε όλα τα εγκλήματα που έχουν προκαλέσει βαριά σωματική βλάβη \n",
    "assault_df = crimes_total_df.filter(col(\"crm_cd_desc\").like(\"%AGGRAVATED ASSAULT%\"))\n",
    "\n",
    "#μετατρεπουμε την μεταβλητη απο τύπο Sting σε τύπο int για να εχουμε συγκριση\n",
    "test_df = assault_df.withColumn(\"vict_age_int\", col(\"vict_age\").cast(\"integer\"))\n",
    "\n",
    "###  WITH UDF  ###\n",
    "def age_group(age):\n",
    "    if age<18:\n",
    "        return \"Children\"\n",
    "    elif age < 25 :\n",
    "        return \"Youths\"\n",
    "    elif age < 65: \n",
    "        return \"Adults\"\n",
    "    else :\n",
    "        return \"Seniors\"\n",
    "\n",
    "# Register the UDF\n",
    "classify_victim_age_udf = udf(age_group, StringType())\n",
    "age_groups_df = test_df \\\n",
    "    .withColumn(\"age_group\", classify_victim_age_udf(col(\"vict_age_int\"))).groupBy(\"age_group\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "\n",
    "### WITHOUT UDF ###\n",
    "# employees_yearly_df = employees_df \\\n",
    "#     .withColumn(\"yearly\", (14*col(\"salary\")+col(\"bonus\"))).select(\"name\", \"yearly\")\n",
    "####################\n",
    "\n",
    "age_groups_df.show()\n",
    "end_time=time.time()\n",
    "print(\"Dataframe using UDF API Execution time for Query 1: {:.4f} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c757e375-56fa-4f40-8e2d-f96bd64b2ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7590275f2243159267cdfc30813f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "invalid syntax (<stdin>, line 1)\n",
      "  File \"<stdin>\", line 1\n",
      "    ---------+------+\n",
      "                     ^\n",
      "SyntaxError: invalid syntax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "---------+------+\n",
    "|   Adults|121660|\n",
    "|    Youth| 33758|\n",
    "| Children| 16009|\n",
    "|  Seniors|  6011|\n",
    "|  Unknown|     5|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d581614-38d7-4076-a8bc-6ee94902ce85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b951c-ed64-4078-a175-172df022eaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
