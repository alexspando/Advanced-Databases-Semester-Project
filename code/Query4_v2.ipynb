{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acf98a0-ca33-4808-884d-598dd3dcf180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.memory': '4g', 'spark.executor.cores': '2'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>847</td><td>application_1761923966900_0859</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0859/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-189.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0859_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>848</td><td>application_1761923966900_0860</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0860/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-97.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0860_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>849</td><td>application_1761923966900_0861</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0861/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-160.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0861_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>850</td><td>application_1761923966900_0862</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0862/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-189.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0862_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>851</td><td>application_1761923966900_0863</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0863/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-189.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0863_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>856</td><td>application_1761923966900_0868</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0868/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-172.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0868_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>857</td><td>application_1761923966900_0869</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0869/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-175.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0869_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"2\",\n",
    "        \"spark.executor.memory\": \"4g\",\n",
    "        \"spark.executor.cores\": \"2\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7f0c63-56d3-4334-9522-aaba2a657ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>858</td><td>application_1761923966900_0870</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-24.eu-central-1.compute.internal:20888/proxy/application_1761923966900_0870/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-133.eu-central-1.compute.internal:8042/node/containerlogs/container_1761923966900_0870_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf61f2b5ccf34bd79eeece67af84e210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4439643c0a95478fae5f1f17f1253618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+--------------------+\n",
      "|division        |crime_count|avg_distance        |\n",
      "+----------------+-----------+--------------------+\n",
      "|HOLLYWOOD       |214157     |0.020436213557045942|\n",
      "|VAN NUYS        |212495     |0.028654072511946835|\n",
      "|WILSHIRE        |199273     |0.026311034884955457|\n",
      "|SOUTHWEST       |187418     |0.0215807431211962  |\n",
      "|OLYMPIC         |181990     |0.017306293320735557|\n",
      "|NORTH HOLLYWOOD |171974     |0.026116102217477895|\n",
      "|77TH STREET     |168030     |0.016587006268602506|\n",
      "|PACIFIC         |158587     |0.03752453485777577 |\n",
      "|CENTRAL         |155553     |0.009875953835326358|\n",
      "|SOUTHEAST       |153569     |0.0241625608528956  |\n",
      "|RAMPART         |150615     |0.014739396233047736|\n",
      "|TOPANGA         |150239     |0.032446654666430604|\n",
      "|WEST VALLEY     |132004     |0.02899430194557513 |\n",
      "|HARBOR          |130520     |3.0007647359015697  |\n",
      "|FOOTHILL        |122935     |0.041266265564586554|\n",
      "|WEST LOS ANGELES|121644     |0.029818699889031575|\n",
      "|HOLLENBECK      |120059     |0.02637900675359736 |\n",
      "|MISSION         |111032     |0.034982605367859305|\n",
      "|NEWTON          |109570     |0.015894303929832602|\n",
      "|NORTHEAST       |106135     |0.03906315361123134 |\n",
      "+----------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Execution time for Query 4 (2 core, 2 executors, 4GB memory ): 36.4259 sec"
     ]
    }
   ],
   "source": [
    "from sedona.spark import SedonaContext\n",
    "from sedona.register.geo_registrator import SedonaRegistrator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import *\n",
    "from sedona.sql.types import GeometryType\n",
    "from sedona.sql import ST_Point, ST_Distance\n",
    "from pyspark.sql.functions import min as sql_min\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "# -------------------------------------------------\n",
    "# 1. Spark + Sedona setup\n",
    "# -------------------------------------------------\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Query Nearest Police Station\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(spark)\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Load crimes\n",
    "# -------------------------------------------------\n",
    "crimes_schema = StructType([\n",
    "    StructField(\"dr_no\", StringType()),\n",
    "    StructField(\"date_rptd\", StringType()),\n",
    "    StructField(\"date_occ\", StringType()),\n",
    "    StructField(\"time_occ\", StringType()),\n",
    "    StructField(\"area\", StringType()),\n",
    "    StructField(\"area_name\", StringType()),\n",
    "    StructField(\"rpt_dist_no\", StringType()),\n",
    "    StructField(\"part_1_2\", IntegerType()),\n",
    "    StructField(\"crm_cd\", StringType()),\n",
    "    StructField(\"crm_cd_desc\", StringType()),\n",
    "    StructField(\"mocodes\", StringType()),\n",
    "    StructField(\"vict_age\", StringType()),\n",
    "    StructField(\"vict_sex\", StringType()),\n",
    "    StructField(\"vict_descent\", StringType()),\n",
    "    StructField(\"premis_cd\", StringType()),\n",
    "    StructField(\"premis_desc\", StringType()),\n",
    "    StructField(\"weapon_used_cd\", StringType()),\n",
    "    StructField(\"weapon_desc\", StringType()),\n",
    "    StructField(\"status\", StringType()),\n",
    "    StructField(\"status_desc\", StringType()),\n",
    "    StructField(\"crm_cd_1\", StringType()),\n",
    "    StructField(\"crm_cd_2\", StringType()),\n",
    "    StructField(\"crm_cd_3\", StringType()),\n",
    "    StructField(\"crm_cd_4\", StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"cross_street\", StringType()),\n",
    "    StructField(\"lat\", FloatType()),\n",
    "    StructField(\"lon\", FloatType()),\n",
    "])\n",
    "\n",
    "crimes_2010_2019_df = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\",\n",
    "    header=False, schema=crimes_schema\n",
    ")\n",
    "\n",
    "crimes_2020_2025_df = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\",\n",
    "    header=False, schema=crimes_schema\n",
    ")\n",
    "\n",
    "# Combine datasets\n",
    "crimes_total_df = crimes_2010_2019_df.union(crimes_2020_2025_df)\n",
    "\n",
    "# Filter records with coordinates\n",
    "crimes_points = crimes_total_df \\\n",
    "    .filter(col(\"lat\").isNotNull() & col(\"lon\").isNotNull()) \\\n",
    "    .withColumn(\"crime_geom\", ST_Point(col(\"lon\"), col(\"lat\")))\n",
    "\n",
    "\n",
    "police_df = spark.read.csv(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv\",\n",
    "    header=True, inferSchema=True\n",
    ").select(\n",
    "    col(\"DIVISION\").alias(\"division\"),\n",
    "    col(\"X\").alias(\"lon\"),\n",
    "    col(\"Y\").alias(\"lat\")\n",
    ")\n",
    "\n",
    "# Convert to geometry\n",
    "police_points = police_df.withColumn(\n",
    "    \"police_geom\",\n",
    "    ST_Point(col(\"lon\"), col(\"lat\"))\n",
    ")\n",
    "\n",
    "\n",
    "joined = crimes_points.crossJoin(police_points) \\\n",
    "    .withColumn(\"distance\", ST_Distance(col(\"crime_geom\"), col(\"police_geom\"))) \\\n",
    "    .select(\n",
    "        col(\"dr_no\"),\n",
    "        col(\"division\"),\n",
    "        col(\"distance\")\n",
    "    )\n",
    "\n",
    "j = joined.alias(\"j\")\n",
    "\n",
    "# 1. Minimum distance per crime\n",
    "min_dist = j.groupBy(col(\"j.dr_no\")).agg(\n",
    "    sql_min(\"j.distance\").alias(\"min_distance\")\n",
    ").alias(\"m\")\n",
    "\n",
    "# 2. Join χωρίς ambiguous dr_no\n",
    "nearest = j.join(\n",
    "    min_dist,\n",
    "    (col(\"j.dr_no\") == col(\"m.dr_no\")) &\n",
    "    (col(\"j.distance\") == col(\"m.min_distance\")),\n",
    "    \"inner\"\n",
    ").select(\n",
    "    col(\"j.dr_no\").alias(\"dr_no\"),\n",
    "    col(\"j.division\").alias(\"division\"),\n",
    "    col(\"j.distance\").alias(\"distance_to_station\")\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Compute crime_count + avg_distance per division\n",
    "# -------------------------------------------------\n",
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "division_stats = nearest.groupBy(\"division\").agg(\n",
    "    count(\"dr_no\").alias(\"crime_count\"),\n",
    "    avg(\"distance_to_station\").alias(\"avg_distance\")\n",
    ").orderBy(col(\"crime_count\").desc())\n",
    "\n",
    "division_stats.show(truncate=False)\n",
    "division_stats.explain(\"formatted\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution time for Query 4 (2 core, 2 executors, 4GB memory ): {:.4f} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182ec40-9480-4661-82e1-af7e683ada6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
